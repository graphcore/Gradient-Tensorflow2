{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B55MX2H24QJ7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Physics Informed Neural Networks (PINNs) - 2D Wave Equation\n",
    "\n",
    "Copyright (c) 2022 UKAEA. All rights reserved.\n",
    "\n",
    "Copyright (c) 2022 Graphcore Ltd. All rights reserved.\n",
    "\n",
    "This notebook contains a modified version of the work in https://github.com/farscape-project/PINNs_Benchmark/blob/main/PINN_Wave_TF-2.ipynb, modified by Graphcore Ltd so that it can be run with the latest version of Graphcore's [Poplar (TM) SDK](https://docs.graphcore.ai/projects/sdk-overview/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "This file has been modified by Graphcore Ltd.\n",
    "\n",
    "[![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)\n",
    "\n",
    "\n",
    "| Framework    |  Domain           | Tasks      | Model | Datasets | Workflow |   Number of IPUs   | Execution time |\n",
    "|--------------|-------------------|------------|-------|----------|----------|--------------|--------------|\n",
    "| TensorFlow 2 | AI for Simulation | PDE solver | MLP   | None     | training, inference | 4 | ~5 minutes  |\n",
    "\n",
    "## Methods\n",
    "\n",
    "This example shows training a Neural Network to converge towards a well-defined solution of a PDE by way of minimising for the residuals across the spatio-temporal domain.\n",
    "\n",
    "Initial and Boundary conditions are met by introducing them into the loss function along with the PDE residuals. \n",
    "\n",
    "The PDE is defined over 2D spatial (`x`, `y`) and 1D temporal (`t`) dimensions, with the time dimension divided into a finite number of time-steps. \n",
    "\n",
    "Numerical Method - Spectral Solver using FFT. <br>\n",
    "Code taken from http://people.bu.edu/andasari/courses/numericalpython/Week12Lecture21/Spectral_wave2.py\n",
    "\n",
    "Equation: \n",
    "\n",
    "```\n",
    "u_tt = u_xx + u_yy on [-1,1] x [-1,1] \n",
    "```\n",
    "\n",
    "Dirichlet Boundary Conditions : \n",
    "```\n",
    "u=0\n",
    "```\n",
    "\n",
    "Initial Distribution :\n",
    "```\n",
    " u(x,y,t=0) = exp( -40((x-0.4)^2 + y^2) )\n",
    " ```\n",
    "\n",
    "Initial Velocity Condition : \n",
    "```\n",
    "u_t(x,y,t=0) = 0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "The best way to run this demo is on Paperspace Gradient's cloud IPUs, since everything is already set up for you.\n",
    "\n",
    "[![Run on Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://ipu.dev/MUD3GR) UPDATE ME WITH LINK!!!\n",
    "\n",
    "To run the demo using other IPU hardware, you need to have the Poplar SDK enabled. Refer to the [Getting Started guide](https://docs.graphcore.ai/en/latest/getting-started.html#getting-started) for your system for details on how to enable the Poplar SDK. Also refer to the [Jupyter Quick Start guide](https://docs.graphcore.ai/projects/jupyter-notebook-quick-start/en/latest/index.html) for how to set up Jupyter to be able to run this notebook on a remote IPU machine.\n",
    "\n",
    "## Install dependencies\n",
    "\n",
    "First we need to install the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical Solution\n",
    "\n",
    "In this first step we build the numerical solution by solving the Wave Equation using a spectral solver implemented on the CPU using numpy.\n",
    "\n",
    "The solution will not form the training data but will be used for comparing against the PINN solution.\n",
    "\n",
    "First we import the necessary Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1646144452427,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "Vm_Q-_6_6wH0",
    "outputId": "d060ebef-4bf9-498d-9e96-c1e3b25b7ab4",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class WaveEquation:\n",
    "    def __init__(self, N, T):\n",
    "        self.N = N\n",
    "        self.T = T\n",
    "        self.x0 = -1.0\n",
    "        self.xf = 1.0\n",
    "        self.y0 = -1.0\n",
    "        self.yf = 1.0\n",
    "        self.initialization()\n",
    "        self.initCond() \n",
    "        \n",
    "    def initialization(self):\n",
    "        k = np.arange(self.N + 1)\n",
    "        self.x = np.cos(k*np.pi/self.N)\n",
    "        self.y = self.x.copy()\n",
    "        self.xx, self.yy = np.meshgrid(self.x, self.y)\n",
    "        \n",
    "        self.dt = 6/self.N**2\n",
    "        self.plotgap = round((1/3)/self.dt)\n",
    "        self.dt = (1/3)/self.plotgap\n",
    "        \n",
    "    def initCond(self):\n",
    "        self.vv = np.exp(-40*((self.xx-0.4)**2 + self.yy**2))\n",
    "        self.vvold = self.vv.copy()\n",
    "\n",
    "    def solve(self):\n",
    "        u_list = []  \n",
    "        tc = 0\n",
    "        nstep = round(self.T/self.dt) + 1 # nstep = round(3*self.plotgap+1)\n",
    "        \n",
    "        while tc < nstep:   \n",
    "            xxx = np.arange(self.x0, self.xf+1/16, 1/16)\n",
    "            yyy = np.arange(self.y0, self.yf+1/16, 1/16)\n",
    "            vvv = interpolate.interp2d(self.x, self.y, self.vv, kind='cubic')\n",
    "            Z = vvv(xxx, yyy)\n",
    "            xxf, yyf = np.meshgrid(np.arange(self.x0,self.xf+1/16,1/16), np.arange(self.y0,self.yf+1/16,1/16))         \n",
    "            uxx = np.zeros((self.N+1, self.N+1))\n",
    "            uyy = np.zeros((self.N+1, self.N+1))\n",
    "            ii = np.arange(1, self.N)\n",
    "            \n",
    "            for i in range(1, self.N):\n",
    "                v = self.vv[i,:]\n",
    "                V = np.hstack((v, np.flipud(v[ii])))\n",
    "                U = np.fft.fft(V).real\n",
    "                r1 = np.arange(self.N)\n",
    "                r2 = 1j*np.hstack((r1, 0, -r1[:0:-1]))*U\n",
    "                W1 = np.fft.ifft(r2).real\n",
    "                s1 = np.arange(self.N+1)\n",
    "                s2 = np.hstack((s1, -s1[self.N-1:0:-1]))\n",
    "                s3 = -s2**2*U\n",
    "                W2 = np.fft.ifft(s3).real\n",
    "                uxx[i,ii] = W2[ii]/(1-self.x[ii]**2) - self.x[ii]*W1[ii]/(1-self.x[ii]**2)**(3/2)\n",
    "                \n",
    "            for j in range(1, self.N):\n",
    "                v = self.vv[:,j]\n",
    "                V = np.hstack((v, np.flipud(v[ii])))\n",
    "                U = np.fft.fft(V).real\n",
    "                r1 = np.arange(self.N)\n",
    "                r2 = 1j*np.hstack((r1, 0, -r1[:0:-1]))*U\n",
    "                W1 = np.fft.ifft(r2).real\n",
    "                s1 = np.arange(self.N+1)\n",
    "                s2 = np.hstack((s1, -s1[self.N-1:0:-1]))\n",
    "                s3 = -s2**2*U\n",
    "                W2 = np.fft.ifft(s3).real\n",
    "                uyy[ii,j] = W2[ii]/(1-self.y[ii]**2) - self.y[ii]*W1[ii]/(1-self.y[ii]**2)**(3/2)\n",
    "                \n",
    "            vvnew = 2*self.vv - self.vvold + self.dt**2*(uxx+uyy)\n",
    "            self.vvold = self.vv.copy()\n",
    "            self.vv = vvnew.copy()\n",
    "            tc += 1\n",
    "            u_list.append(Z)\n",
    "        return np.asarray(u_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def main(N, T):\n",
    "    simulator = WaveEquation(N, T) \n",
    "    u_sol = simulator.solve()\n",
    "    return u_sol\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    time_end = 1 #Upto how many seconds we would like to simulate. \n",
    "    N = 30 #Spatial Discretisation. \n",
    "    dt =  6/N**2 #N and dt are fixed for ensuring numerical stability. \n",
    "    k = 30 + 1\n",
    "\n",
    "    u_sol = main(N, time_end)    \n",
    "    \n",
    "\n",
    "    lb = np.asarray([-1.0, -1.0, 0]) #[x, y, t] Lower Bounds of the domain\n",
    "    ub = np.asarray([1.0, 1.0, time_end]) #Upper Bounds of the domain/ \n",
    "    \n",
    "    x = np.arange(-1, 1+1/16, 1/16)\n",
    "    y = x.copy()\n",
    "    t = np.arange(lb[2], ub[2]+dt, dt)\n",
    "    \n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    u_ic = np.exp(-40*((xx-0.4)**2 + yy**2)) #Initial Gaussian Distribution. \n",
    "    \n",
    "    U_sol = u_sol\n",
    "\n",
    "    grid_length = len(x)\n",
    "    \n",
    "    #Storing the problem and solution information.\n",
    "    df_dict = {'x': x,\n",
    "               'y': y,\n",
    "               't': t,\n",
    "               'lower_range': lb,\n",
    "               'upper_range': ub,\n",
    "               'U_sol': U_sol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PINN to Solve the 2D Wave Equation\n",
    "\n",
    "Now we will train a PINN to provide a solution to the 2D wave equation defined above. There is no dataset, since the loss functions are based on well-defined initial and boundary conditions, and the PDE describing the system over its domain is known.\n",
    "\n",
    "First, we import the necessary Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7354,
     "status": "ok",
     "timestamp": 1646144459774,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "OyGUiXVtNom4",
    "outputId": "371fdbe3-4875-4296-9558-a7fa0579cd6f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib.animation as animation\n",
    "%matplotlib widget\n",
    "plt.rcParams['figure.dpi'] = 250\n",
    "import operator\n",
    "from functools import reduce \n",
    "\n",
    "from pyDOE import lhs\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import layers, activations\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.python import ipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1646144460153,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "NnTs3GVUNom4",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the random seed. \n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PINN Model\n",
    "\n",
    "We define the PINN model using the Keras Model API.\n",
    "\n",
    "The model consists of five fully-connected layers, with the four hidden layers using a `tanh` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3348,
     "status": "ok",
     "timestamp": 1646144463497,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "b-iWMZp0yydE",
    "outputId": "cd4c416c-06fe-471a-d002-2ebe0328cc34",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class PINN(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(100, activation=tf.nn.tanh)\n",
    "    self.dense2 = tf.keras.layers.Dense(100, activation=tf.nn.tanh)\n",
    "    self.dense3 = tf.keras.layers.Dense(100, activation=tf.nn.tanh)\n",
    "    self.dense4 = tf.keras.layers.Dense(100, activation=tf.nn.tanh)\n",
    "    self.output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    x = self.dense3(x)\n",
    "    x = self.dense4(x)\n",
    "    x = self.output_layer(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Latin Hypercube Sampling (LHS)\n",
    "\n",
    "LHS sampling is used to generate random points over the `(x,y,t)` domain of interest for the PDE.\n",
    "\n",
    "These coordinates, as well as similarly-generated points representing the initial conditions (`t=0`) and boundary conditions (`x=x_min`, `x=x_max`, `y=y_min`, `y=y_max`), will be used to evaluate the performance of the PINN during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1646144463497,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "0JKkNH-4Nom5",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Specifying the Domain of Interest. \n",
    "x_range = [-1.0, 1.0]\n",
    "y_range = [-1.0, 1.0]\n",
    "t_range = [0.0, time_end]\n",
    "D = 1.0\n",
    "\n",
    "lb = np.asarray([x_range[0], y_range[0], t_range[0]]) #lower bounds\n",
    "ub = np.asarray([x_range[1], y_range[1], t_range[1]]) #Upper bounds\n",
    "\n",
    "#Fucnction to sample collocation points across the spatio-temporal domain using a Latin Hypercube\n",
    "def LHS_Sampling(N):\n",
    "    return lb + (ub-lb)*lhs(3, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss Functions: Evaluating the PDE and its initial/boundary conditions\n",
    "\n",
    "We define multiple loss functions for the PINN model, each representing either the PDE or one of its initial/boundary conditions.\n",
    "\n",
    "#### PDE Loss Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1646144463498,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "2JMPPS2wNom6",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Domain Loss Function - measuring the deviation from the PDE functional. \n",
    "def pde(X):\n",
    "    x = X[:, 0:1]\n",
    "    y = X[:, 1:2]\n",
    "    t = X[:, 2:3]\n",
    "    u = model(tf.concat([x,y,t], 1))\n",
    "\n",
    "    u_x = tf.gradients(u,x)[0]\n",
    "    u_xx = tf.gradients(u_x, x)[0]\n",
    "    u_y = tf.gradients(u,y)[0]\n",
    "    u_yy = tf.gradients(u_y, y)[0]\n",
    "    u_t = tf.gradients(u,t)[0]\n",
    "    u_tt = tf.gradients(u_t, t)[0]\n",
    "    pde_loss = u_tt - D*(u_xx + u_yy)\n",
    "\n",
    "    return tf.reduce_mean(tf.square(pde_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Boundary Condition Loss Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Boundary Loss Function - measuring the deviation from boundary conditions for f(x_lim, y_lim, t)\n",
    "def boundary(X):\n",
    "    u = model(X)\n",
    "    bc_loss = u - 0\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(bc_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Initial Condition Loss Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Initial Velocity Conditions :\n",
    "def initial_velocity(X):\n",
    "    x = X[:, 0:1]\n",
    "    y = X[:, 1:2]\n",
    "    t = X[:, 2:3]\n",
    "    u = model(tf.concat([x,y,t], 1))\n",
    "\n",
    "    u_t = tf.gradients(u, t)[0]\n",
    "    initial_cond_loss = u_t\n",
    "\n",
    "    return tf.reduce_mean(tf.square(initial_cond_loss))\n",
    "\n",
    "#Reconstruction Loss Function - measuring the deviation from the actual output. Used to calculate the initial loss\n",
    "def reconstruction(X, Y):\n",
    "    u = model(X)\n",
    "    recon_loss = u-Y\n",
    "    return tf.reduce_mean(tf.square(recon_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preparing the input data\n",
    "\n",
    "Here we prepare the input tensors for the initial (`t=0`), boundary and domain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646144463498,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "Wst2TbE_Nom6",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Samples taken from each region for optimisation purposes. \n",
    "N_i = 1000 #Initial\n",
    "N_b = 1000 #Boundary\n",
    "N_f = 40000 #Domain\n",
    "batch_size = 10000 # Split the Domain samples into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646144463499,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "SCIwi0b_Nom7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the inputs and outputs for comparison with the numerical solution. \n",
    "u = np.asarray(u_sol)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XY_star = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))\n",
    "T_star = np.expand_dims(np.repeat(t, len(XY_star)), 1)\n",
    "X_star_tiled = np.tile(XY_star, (len(t), 1))\n",
    "\n",
    "X_star = np.hstack((X_star_tiled, T_star))\n",
    "u_actual = np.expand_dims(u.flatten(),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646144463499,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "LMxuNAYQNom7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Data for Initial Input\n",
    "X_IC = np.hstack((XY_star, np.zeros(len(XY_star)).reshape(len(XY_star), 1)))\n",
    "u_IC = u[0].flatten()\n",
    "u_IC = np.expand_dims(u_IC, 1)\n",
    "\n",
    "idx = np.random.choice(X_IC.shape[0], N_i, replace=False) \n",
    "X_i = X_IC[idx]\n",
    "u_i = u_IC[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646144463500,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "1SDTuTQkNom7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Data for Boundary Input\n",
    "\n",
    "X_left = LHS_Sampling(N_b)\n",
    "X_left[:,0:1] = x_range[0]\n",
    "\n",
    "X_right = LHS_Sampling(N_b)\n",
    "X_right[:,0:1] = x_range[1]\n",
    "\n",
    "X_bottom = LHS_Sampling(N_b)\n",
    "X_bottom[:,1:2] = y_range[0]\n",
    "\n",
    "X_top = LHS_Sampling(N_b)\n",
    "X_top[:,1:2] = y_range[1]\n",
    "\n",
    "X_b = np.vstack((X_right, X_top, X_left, X_bottom))\n",
    "np.random.shuffle(X_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646144463500,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "N8eKM6ifNom7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Data for Domain Input\n",
    "X_f = LHS_Sampling(N_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646144463500,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "xxi5nsqINom7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Converting to tensors \n",
    "X_i = tf.convert_to_tensor(X_i, dtype=tf.float32)\n",
    "Y_i = tf.convert_to_tensor(u_i, dtype=tf.float32)\n",
    "X_b = tf.convert_to_tensor(X_b, dtype=tf.float32)\n",
    "X_f = tf.convert_to_tensor(X_f, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensorFlow Dataset\n",
    "\n",
    "We wrap the input data inside a TensorFlow Dataset object, allowing us to easily batch the data as well as utilise optimisation techniques such as dataset prefetching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    # We split X_f up into batches in order to fit into IPU memory.\n",
    "    # Each batch is fed to a different IPU in order to train in a data-parallel fashion\n",
    "    num_batches = N_f // batch_size\n",
    "    print(\"Batching the domain into {} batches of size {}\".format(num_batches, batch_size))\n",
    "    X_f_batched = tf.split(X_f, num_batches, axis=0)\n",
    "    \n",
    "    def gen():\n",
    "        for i in range(num_batches):\n",
    "            yield X_i, X_b, X_f_batched[i]\n",
    "    \n",
    "    # Wrap in TF dataset so Poplar knows what shapes to expect\n",
    "    ds = tf.data.Dataset.from_generator(gen,\n",
    "                                        output_shapes=((N_i, 3), (4*N_b, 3), (N_f // num_batches, 3)),\n",
    "                                        output_types=(tf.float32, tf.float32, tf.float32))\n",
    "    \n",
    "    # Performance optimisations (using TF dataset allows us to use these)\n",
    "    ds = ds.batch(1, drop_remainder=True)\n",
    "    ds = ds.repeat().prefetch(100)\n",
    "    \n",
    "    # Inference dataset\n",
    "    X_star_cast = tf.convert_to_tensor(X_star, dtype=tf.float32)\n",
    "    ds_star = tf.data.Dataset.from_tensor_slices((X_star_cast)).batch(164439, drop_remainder=True).repeat()\n",
    "    \n",
    "    return ds, ds_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ds, ds_star = create_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Training Function\n",
    "\n",
    "The `train_step` function defines the part of our script which we wish to run on the IPU itself. As part of each training step step we perform a forward pass, calculate the losses and gradients, and perform the weight update over the model.\n",
    "\n",
    "### On-Device Loop: `steps_per_execution`\n",
    "\n",
    "On the IPU we can loop over `steps_per_execution` training steps in a single call to the hardware, by placing the code inside a `for` loop.\n",
    "\n",
    "As a result, the IPU spends a greater fraction of the time doing compute and less time waiting for data from the host, thus improving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def train_step(model, iterator, optimizer, outfeed_queue, steps_per_execution):\n",
    "    for _ in tf.range(steps_per_execution):\n",
    "        X = next(iterator)\n",
    "        X_i = X[0][0]\n",
    "        X_b = X[1][0]\n",
    "        X_f = X[2][0]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            initial_loss = reconstruction(X_i, Y_i) + initial_velocity(X_i)\n",
    "            boundary_loss = boundary(X_b)\n",
    "            domain_loss = pde(X_f)\n",
    "\n",
    "            loss = initial_loss + boundary_loss + domain_loss   \n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        outfeed_queue.enqueue([initial_loss, boundary_loss, domain_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## IPUConfig: Configure the IPU Device\n",
    "\n",
    "We construct an instance of the `IPUConfig` class to request one or multiple IPUs and attach our program to these.\n",
    "\n",
    "We request `4` IPUs, but the model can be trained using just a single IPU. As such, TensorFlow will automatically replicate the model across the IPUs, allowing for easy data-parallel training.\n",
    "\n",
    "We also create an `IPUStrategy`, which allows us to control which parts of our program runs on the IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# configure IPU system\n",
    "num_ipus = 4\n",
    "cfg = ipu.config.IPUConfig()\n",
    "cfg.auto_select_ipus = num_ipus\n",
    "cfg.configure_ipu_system()\n",
    "\n",
    "strategy = ipu.ipu_strategy.IPUStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We construct the model inside the scope of this IPU Strategy, indicating that the entire model be compiled for and placed on the IPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = PINN()\n",
    "    model.build(input_shape=(None,3))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Now we can train the model, looping over the total number of training steps in multiples of `steps_per_execution`.\n",
    "\n",
    "We construct the optimiser and the `iterator` and `outfeed_queue` objects used to send data to/from the IPU asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 980687,
     "status": "ok",
     "timestamp": 1646145444178,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "OOtgWHSnNom8",
    "outputId": "20b76c50-0acf-4dce-b590-7d2fe4b3ca97",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20000 #Number of Epochs for the training loop.\n",
    "steps_per_execution = 2000 #Number of training steps to perform in an on-device loop\n",
    "loss_list = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with strategy.scope():\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3, beta_1=.90)\n",
    "    optimizer = ipu.optimizers.CrossReplicaOptimizer(optimizer)\n",
    "    \n",
    "    iterator = iter(ds)\n",
    "    \n",
    "    outfeed_queue = ipu.ipu_outfeed_queue.IPUOutfeedQueue()\n",
    "    \n",
    "    for it in range(0, epochs, steps_per_execution):\n",
    "        strategy.run(train_step, args=[model, iterator, optimizer, outfeed_queue, steps_per_execution])\n",
    "\n",
    "        initial_loss, boundary_loss, domain_loss = outfeed_queue.dequeue()\n",
    "        loss_list.extend(initial_loss + boundary_loss + domain_loss)\n",
    "        \n",
    "        print('Epoch: %d/%d, Init: %.3e, Bound: %.3e, Domain: %.3e' \\\n",
    "              % (it+steps_per_execution, epochs, np.mean(initial_loss), np.mean(boundary_loss), np.mean(domain_loss)))\n",
    "\n",
    "\n",
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting the Training Loss\n",
    "\n",
    "The plot below shows how the overall training loss decreases as the model trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "loss_plot = plt.figure(figsize=(5, 3))\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('L2 Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Inference\n",
    "\n",
    "The function below defines an inference step, performing only a forward pass over the model and returning the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def inference_step(model, iterator, outfeed_queue):\n",
    "    X = next(iterator)\n",
    "    u_pred = model(X)\n",
    "    \n",
    "    outfeed_queue.enqueue(u_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset contains an odd number of elements, and we can process it in a single batch on the IPU. As such we use a single IPU, and so we create a fresh IPU Config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# New IPUConfig for inference\n",
    "cfg = ipu.config.IPUConfig()\n",
    "cfg.auto_select_ipus = 1\n",
    "cfg.configure_ipu_system()\n",
    "\n",
    "strategy = ipu.ipu_strategy.IPUStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Inference\n",
    "\n",
    "We then run inference over the test dataset and compute the L2 Error between the PINN output and the numerical solution calculated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1646148379770,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "XDLinqs-Nom8",
    "outputId": "83b1e6c1-935f-40c7-f559-49a48f947cc6",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    iterator = iter(ds_star)\n",
    "    \n",
    "    outfeed_queue = ipu.ipu_outfeed_queue.IPUOutfeedQueue()\n",
    "    \n",
    "    strategy.run(inference_step, args=[model, iterator, outfeed_queue])\n",
    "    \n",
    "    u_pred = outfeed_queue.dequeue()\n",
    "\n",
    "l2_error = np.mean((u_actual - u_pred)**2)\n",
    "\n",
    "print('Training Time: %d seconds, L2 Error: %.3e' % (train_time, l2_error))\n",
    "\n",
    "u_pred = u_pred.numpy().reshape(len(u), grid_length, grid_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing the Results with the Numerical Solution\n",
    "\n",
    "Finally we can visually compare the PINN-generated results with the numerical solution calculated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1646145445139,
     "user": {
      "displayName": "Vignesh G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giz9VGq-UNkhs1wUnNSg1fEYEvmjriifKR-FkM0kw=s64",
      "userId": "09618553731198744562"
     },
     "user_tz": -330
    },
    "id": "AwqIcU3EqA28",
    "outputId": "7ad6ce6d-9e87-448d-aa97-5dc31289ebdc",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "u_field = u_sol\n",
    "fig = plt.figure(figsize=[5,3])\n",
    "ax = fig.add_subplot(2,3,1)\n",
    "ax.imshow(u_field[0])\n",
    "ax.title.set_text('Initial')\n",
    "ax.set_ylabel('Solution')\n",
    "ax = fig.add_subplot(2,3,2)\n",
    "ax.imshow(u_field[int(len(t)/2)])\n",
    "ax.title.set_text('Middle')\n",
    "ax = fig.add_subplot(2,3,3)\n",
    "ax.imshow(u_field[-1])\n",
    "ax.title.set_text('Final')\n",
    "\n",
    "u_field = u_pred\n",
    "ax = fig.add_subplot(2,3,4)\n",
    "ax.imshow(u_field[0])\n",
    "ax.set_ylabel('PINN')\n",
    "ax = fig.add_subplot(2,3,5)\n",
    "ax.imshow(u_field[int(len(t)/2)])\n",
    "ax = fig.add_subplot(2,3,6)\n",
    "ax.imshow(u_field[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cooler: Animation shows progression of numerical and PINN solutions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plt_data():\n",
    "    for i in range(0, len(t), 2):\n",
    "        data_sol = u_sol[i]\n",
    "        data_pred = u_pred[i]\n",
    "\n",
    "        yield i, data_sol, data_pred\n",
    "\n",
    "def update_plot(data):\n",
    "    frame_idx, data_sol, data_pred = data\n",
    "\n",
    "    im_sol.set_data(data_sol)\n",
    "    im_sol.autoscale()\n",
    "    im_pred.set_data(data_pred)\n",
    "    im_pred.autoscale()\n",
    "    plt.suptitle('Time Step {} of {}'.format(frame_idx, len(t)))\n",
    "    return im_sol, im_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[5,3])\n",
    "\n",
    "ax_sol = fig.add_subplot(1,2,1)\n",
    "im_sol = ax_sol.imshow(u_sol[0])\n",
    "ax_sol.title.set_text('Solution')\n",
    "\n",
    "ax_pred = fig.add_subplot(1,2,2)\n",
    "im_pred = ax_pred.imshow(u_pred[0])\n",
    "ax_pred.title.set_text('PINN')\n",
    "plt.suptitle('Time Step {} of {}'.format(0, len(t)))\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, plt_data, blit=True, interval=50,repeat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoother: we can save this as a gif to display more smoothly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "writergif = animation.PillowWriter(fps=10)\n",
    "anim.save('PINN.gif', dpi=600, writer=writergif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"PINN.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "PINN_Wave_TF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "70f7614ef8102c044ed0e400f2b90fcae8d818a5e15d6a5cbbace57cc919388e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
