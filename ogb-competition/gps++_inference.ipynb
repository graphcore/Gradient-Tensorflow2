{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of molecular properties using GPS++ on IPUs (OGB-LSC)\n",
    "==========\n",
    "\n",
    "This notebook demonstrates doing inference on a single sample and the entire test-challenge dataset split using GPS++, the model we used for our OGB-LSC PCQM4Mv2 submission. We will discuss GPS++ in this notebook but for more details on GPS++ see [GPS++: Reviving the Art of Message Passing for Molecular Property Prediction](https://arxiv.org/abs/2302.02947).\n",
    "\n",
    "We will use IPUs for this, which allows us to do inference on the entire validation dataset split in less than a minute.\n",
    "\n",
    "In the process of doing this we will see some of the additional features we generate from the original dataset and feed into the model.\n",
    "\n",
    "### Running on Paperspace\n",
    "\n",
    "The Paperspace environment lets you run this notebook with no set up. To improve your experience we preload datasets and pre-install packages, this can take a few minutes, if you experience errors immediately after starting a session please try restarting the kernel before contacting support. If a problem persists or you want to give us feedback on the content of this notebook, please reach out to through our community of developers using our [slack channel](https://www.graphcore.ai/join-community) or raise a [GitHub issue](https://github.com/gradient-ai/Graphcore-Tensorflow2/issues).\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "* Python packages installed with `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples_utils import notebook_logging\n",
    "%load_ext gc_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example requires building a few things:\n",
    "* An optimised method to get the path lengths of a graph\n",
    "* IPU-optimised grouped gather/scatter operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "import os\n",
    "\n",
    "code_directory = os.getenv(\"OGB_SUBMISSION_CODE\", \".\")\n",
    "! cd {code_directory} && make -C data_utils/feature_generation\n",
    "! cd {code_directory} && make -C static_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Need notebook utils as first import as it modifies the path\n",
    "import notebook_utils\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from argparser import parse_dict\n",
    "from data_utils.load_dataset import CustomGraphData, load_raw_dataset\n",
    "from data_utils.pcq_dataset_28features import smiles2graph_large, CustomPCQM4Mv2Dataset\n",
    "from data_utils.preprocess_dataset import preprocess_dataset\n",
    "from notebook_utils import predict\n",
    "\n",
    "# Set the tensorflow log level\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running on Paperspace we will run some additional configuration steps below. If you aren't running on Paperspace, ensure you have the following environment variables set: `DATASETS_DIR` — location of the dataset, `CHECKPOINT_DIR` — location of any checkpoints, and `POPLAR_EXECUTABLE_CACHE_DIR` — location of any Poplar executable caches. Or you can update the paths manually in the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = os.getenv(\"OGB_CHECKPOINT_DIR\", \".\")\n",
    "dataset_directory = os.getenv(\"OGB_DATASETS_DIR\", \".\")\n",
    "code_directory = Path(os.getenv(\"OGB_SUBMISSION_CODE\", \".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also set a few things to enable us to use the executable caches, saving us from recompiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \".\")\n",
    "os.environ[\"TF_POPLAR_FLAGS\"] = f\"--executable_cache_path='{executable_cache_dir}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a configuration\n",
    "\n",
    "There are three configurations available with the model sizes of 11M (GPS_4layer), 22M (GPS_8layer) and 44M (GPS_16layer).\n",
    "By choosing the model name, the corresponding config path and checkpoint path will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model\n",
    "model_name = \"GPS_4layer\" # choose from [\"GPS_4layer\", \"GPS_8layer\", \"GPS_16layer\"]\n",
    "\n",
    "# Set configs\n",
    "model_dict = {\"GPS_4layer\": \"GPS_PCQ_4gps_11M.yaml\", \n",
    "              \"GPS_8layer\": \"GPS_PCQ_8gps_22M.yaml\",\n",
    "              \"GPS_16layer\": \"GPS_PCQ_16gps_44M.yaml\"}\n",
    "cfg_path = code_directory / \"configs\" / model_dict[model_name]\n",
    "cfg_yaml = yaml.safe_load(cfg_path.read_text())\n",
    "cfg = parse_dict(cfg_yaml)\n",
    "\n",
    "# Set the checkpoint path for the corresponding config\n",
    "sub_directory = model_dict[model_name].split(\".\")[0]\n",
    "checkpoint_path = Path(checkpoint_directory).joinpath(f\"{sub_directory}/model-FINAL\")\n",
    "\n",
    "# Turn off dataset caching for this notebook\n",
    "cfg.dataset.save_to_cache = False\n",
    "cfg.dataset.load_from_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the HOMO-LUMO gap of a single molecule\n",
    "\n",
    "The competition requires predicting the HOMO-LUMO energy gap of a number of molecules. To demonstrate inference with our model on the IPU we will start by predicting the HOMO-LUMO gap of a single molecule.\n",
    "\n",
    "Let's create a smile string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_string = \"CC(NCC[C@H]([C@@H]1CCC(=CC1)C)C)C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how this molecule looks let's visualise this smile string using [rdkit](https://www.rdkit.org/docs/GettingStartedInPython.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles(smile_string)\n",
    "AllChem.Compute2DCoords(mol)\n",
    "Draw.MolToImage(mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert the smile string into some features our model can understand. The competition provides a method to do this (`smiles2graph`). We have written a custom version of this that uses [rdkit](https://www.rdkit.org/docs/GettingStartedInPython.html) to generate more features from the smile string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_obj = smiles2graph_large(smile_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the features that have been created that represent this molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_obj.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the features that have been created:\n",
    "* `edge_index`: The sending and receiving node indices, representing the edges in the graph.\n",
    "* `edge_feat`: The features of each of the edges in the graph.\n",
    "* `node_feat`: The features of each of the nodes in the graph.\n",
    "* `num_nodes`: Number of nodes in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is the size of the node features. They have a size of 28 compared to 9 that the OGB-LSC provided `smiles2graph` function creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_obj[\"node_feat\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will wrap this single graph in our dataset wrapper, which contains some metadata and the dataset object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [graph_obj]\n",
    "graph_raw = CustomGraphData(\n",
    "    graphs,\n",
    "    use_extended_features=True,\n",
    "    use_conformers=True,\n",
    "    trim_chemical_features=cfg.dataset.trim_chemical_features,\n",
    "    use_periods_and_groups=cfg.dataset.use_periods_and_groups,\n",
    "    do_not_use_atomic_number=cfg.dataset.do_not_use_atomic_number,\n",
    "    chemical_node_features=cfg.dataset.chemical_node_features,\n",
    "    chemical_edge_features=cfg.dataset.chemical_edge_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's feed this through our dataset preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_preprocessed = preprocess_dataset(dataset=graph_raw, options=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the additional features created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_single_graph = graph_preprocessed.dataset[0][0]\n",
    "preprocessed_single_graph.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see we now have many more features. Features of note are:\n",
    "\n",
    "* `lap_eig_vals`: The Laplacian eigenvalues used as positional encodings in the model.\n",
    "* `lap_eig_vecs`: - The Laplacian eigenvectors used as positional encodings in the model.\n",
    "* `random_walk_landing_probs`: The random walk feature used as structural encodings in the model.\n",
    "* `shortest_path_distances`: The shortest path distances (2D graph structure information) used as attention bias.\n",
    "* `centrality_encoding`: Degrees of the atoms.\n",
    "* `ogb_conformer`, `ogb_bond_lengths` and `atom_distances` require the 3D position information which is only provided for training data. You will see these values are NaNs or zeros for our inference case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the size of the node features, you will see that is smaller than before. From the 28 features we had before, we have selected 11 based on how beneficial the features were for training. For example, we found the features related to the atomic number group, period and family to be very beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preprocessed_single_graph[\"node_feat\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run on the IPU. We have wrapped this functionality in a single function for simplicity. We encourage you to check the contents of this function.\n",
    "\n",
    "The first time that we run the model in inference on IPUs will require the model to be compiled. This can take a few minutes. We have cached the executable so any subsequent runs we want to do will not require this compile phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the HOMO-LUMO gap of the molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, _ = predict(graph_preprocessed, checkpoint_path, \"test-challenge\", cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the validation dataset split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a single prediction at a time is very inefficient. In this next section we will generate predictions for the entire `valid` dataset split, which is very fast on the IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = (\"valid\",)\n",
    "split_mode = \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load and preprocess the dataset. These steps are the same as those we took when preprocessing the single molecule, but we do the preprocessing only on the molecules in the `valid` dataset split. This will be done from scratch so can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = load_raw_dataset(\n",
    "    cfg.dataset.dataset_name,\n",
    "    dataset_directory,\n",
    "    cfg,\n",
    "    split=cases,\n",
    "    load_ensemble_cache=True,\n",
    "    split_mode=split_mode,\n",
    "    ensemble=True,\n",
    ")\n",
    "graph_data = preprocess_dataset(\n",
    "    dataset=graph_data,\n",
    "    options=cfg,\n",
    "    load_ensemble_cache=False,\n",
    "    folds=cases,\n",
    "    split_mode=split_mode,\n",
    "    ensemble=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get predictions on the entire `valid` dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, ground_truth = predict(graph_data, checkpoint_path, cases[0], cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the mean, variance and histogram of the predictions, and a histogram of the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = predictions.astype(float).mean()\n",
    "std = predictions.astype(float).var()\n",
    "\n",
    "plt.hist(predictions, 30, alpha=0.7, label=\"Predictions\")\n",
    "plt.hist(ground_truth, 30, alpha=0.5, label=\"Ground truth\")\n",
    "plt.xlabel(\"HOMO-LUMO Gap (eV)\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Histogram of HOMO-LUMO gap predictions\")\n",
    "plt.legend()\n",
    "plt.text(5, 15000, f\"mean: {mean:.2f}, std: {std:.2f} \\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compare the predicted values with the true labels and calculate the MAE (mean absolute error) as shown below. The model we test here is a small one (11M parameters). To achieve a better MAE we could select one of the larger models (22M or 44M) and re-run the predictions. For the challenge submission we ran the largest model (44M) with 16 GPS layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_MAE = np.mean(np.abs(np.array(predictions) - np.array(ground_truth)))\n",
    "mean_MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some molecules with their corresponding label and prediction. First, we have to load the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw SMILES strings with corresponding label and select only validation molecules\n",
    "smiles_only = CustomPCQM4Mv2Dataset(\n",
    "    root=dataset_directory, only_smiles=True, split_path=cfg.dataset.split_path\n",
    ")\n",
    "valid_idx = smiles_only.get_idx_split()[\"valid\"]\n",
    "valid_smiles = []\n",
    "for i in valid_idx:\n",
    "    valid_smiles.append(smiles_only[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot random molecules in the `valid` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 6 random indices from validation dataset\n",
    "r_idx = random.sample(range(len(valid_smiles)), 6)\n",
    "# Extract SMILES, RDKit molecular objects, ground_truth labels, and predictions for these molecules\n",
    "Smiles = [valid_smiles[r][0] for r in r_idx]\n",
    "GT = [valid_smiles[r][1] for r in r_idx]\n",
    "Mols = [Chem.MolFromSmiles(r) for r in Smiles]\n",
    "Pred = [predictions[r] for r in r_idx]\n",
    "\n",
    "# Create labels\n",
    "labelList = [\n",
    "    \"True: \" + str(\"%.3f\" % gt) + \"\\v Pred: \" + str(prediction)\n",
    "    for gt, prediction in zip(GT, Pred)\n",
    "]\n",
    "# Display molecules with labels\n",
    "Draw.MolsToGridImage(\n",
    "    Mols,\n",
    "    molsPerRow=3,\n",
    "    legends=[label for label in labelList],\n",
    "    subImgSize=(250, 250),\n",
    "    useSVG=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the mean absolute error compared to a global molecular property such as number of nodes.\n",
    "\n",
    "First, we have to extract the number of nodes from our graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_list = []\n",
    "for i in valid_idx:\n",
    "    num_nodes_list.append(graph_data.dataset[i][0][\"num_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we create a dataframe with columns for ground truth, prediction, and number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    list(zip(ground_truth, predictions, num_nodes_list)),\n",
    "    columns=[\"ground_truth\", \"prediction\", \"num_nodes\"],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the mean HOMO-LUMO gap and mean prediction per molecule size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a line graph\n",
    "plt.plot(\n",
    "    df.groupby(\"num_nodes\")[\"ground_truth\"].mean(),\n",
    "    color=\"red\",\n",
    "    label=\"Mean ground truth\",\n",
    ")\n",
    "plt.plot(\n",
    "    df.groupby(\"num_nodes\")[\"prediction\"].mean(), color=\"green\", label=\"Mean prediction\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.ylabel(\"HOMO-LUMO Gap (eV)\")\n",
    "plt.xlabel(\"Number of Atoms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add the mean absolute error to our dataframe and compare it to the molecule size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MAE to dataframe\n",
    "df[\"mae\"] = np.abs(df[\"ground_truth\"] - df[\"prediction\"])\n",
    "# plot\n",
    "plt.plot(df.groupby(\"num_nodes\")[\"mae\"].mean(), color=\"orange\", label=\"Mean MAE\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Mean Absolute Error (eV)\")\n",
    "plt.xlabel(\"Number of Atoms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our model struggles to predict the HOMO-LUMO gap for larger molecules. However, there are only very few molecules (31 in total) that consist of 40 or more atoms. Therefore, let's see how much molecules of each size contribute to the overall error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MAE to dataframe\n",
    "df[\"mae\"] = np.abs(df[\"ground_truth\"] - df[\"prediction\"])\n",
    "# plot\n",
    "plt.plot(df.groupby(\"num_nodes\")[\"mae\"].size() / len(valid_idx) * 100, color=\"green\")\n",
    "plt.ylabel(\"Contribution in % to final MAE\")\n",
    "plt.xlabel(\"Number of Atoms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow up tasks\n",
    "\n",
    "* Try changing the smile string and seeing what HOMO-LUMO gap is predicted.\n",
    "* Try a larger model (`GPS_PCQ_8gps_22M.yaml` or `GPS_PCQ_16gps_44M.yaml`) and the corresponding checkpoint.\n",
    "* Take a look at the `predict` function to get an understanding of what is required to run on IPUs.\n",
    "* Use the 'test-challenge' split of the dataset to predict HOMO-LUMO gaps for the molecules in the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or head to `notebook_training.ipynb` to try out training the model from scratch using IPUs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import ipu\n",
    "\n",
    "ipu.config.reset_ipu_configuration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.2.0+1262_tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7a9523ff6ed7b4be1e3cbb6e3c37c88f3139ed0d5859d40d308cef69f5b32c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
